{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import nltk.data\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as',\n",
    "               'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot',\n",
    "               'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each',\n",
    "               'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\",\n",
    "               \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i',\n",
    "               \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', \n",
    "               'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other',\n",
    "               'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\",\n",
    "               'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves',\n",
    "               'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through',\n",
    "               'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\",\n",
    "               'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with',\n",
    "               \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves',\n",
    "               'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours',\n",
    "               'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
    "               'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n",
    "               'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "               'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for',\n",
    "               'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up',\n",
    "               'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where',\n",
    "               'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only',\n",
    "               'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\",\n",
    "               'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn',\n",
    "               \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
    "               \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won',\n",
    "               \"won't\", 'wouldn', \"wouldn't\",\n",
    "                'the', 'is', 'a', 'and', 'after', 'as', 'at', 'always', 'between', 'but', 'beyond', 'by', 'can',\n",
    "               'for', 'this', 'that', 'in', 'on', 'mr', 'yes', 'no', 'other', 'said', 'them', 'they', 'who', 'whom',\n",
    "               'where', 'when', 'will', 'would', 'with', 'he', 'his', 'she', 'her', 'you', 'our', 'i', 'am', 'are',\n",
    "               'about', 'been', 'able','ab','an', 'about', 'before','began','begin','not','me','some','up','too','what',\n",
    "               'better', 'did', 'do', 'feel', 'go', 'went', 'how', 'it', 'its', 'itselt', 'into', 'just', 'look', 'like',\n",
    "               'of', 'rv', 'rt', 'out', 'our', 'so', 'soon', 'there', 'these', 'those', 'r', 'to', 'want', 'was', 'we',\n",
    "               'were', 'us', 'went', 'well', 'why', 'yet','when', 'your', 'have','my','be','from','new','has','all','their',\n",
    "               'nor','or','take','took','or','if','years','more','show','here', 'th','now','one','get','facebookrt','pm','day',\n",
    "               'posted','pm','day','people','time','over','dont','today','see','family','join','testify','ceo','should','also',\n",
    "               'most','which','than','had','even','last','many','make','aiera','used','could','wrote','posted','post','much','open',\n",
    "               'may','much','only','app','story','group','vear','year','going','awan','under','crewcrew','aggregateiq',\n",
    "               'facebooks','use','apps','big','ms','ge','g','say','us','two','three','four','five','six','women','man','woman','men'\n",
    "\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business\n",
      "----------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Science\n",
      "----------\n",
      "Sport\n",
      "----------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Politics\n",
      "----------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# stop_words = list(get_stop_words('en'))         #About 900 stopwords\n",
    "# nltk_words = list(stopwords.words('english')) #About 150 stopwords\n",
    "# stop_words.extend(nltk_words)\n",
    "#top_selected = 10\n",
    "PATH_1 = '/Users/maweibin/Desktop/data intensive computing/lab3/part2/data_0425'\n",
    "PATH_2 = '/Users/maweibin/Desktop/data intensive computing/lab3/part2/data_0426'\n",
    "\n",
    "frequency_bus = []\n",
    "frequency_pol = []\n",
    "frequency_spo = []\n",
    "frequency_foo = []\n",
    "\n",
    "def clean_stopwords(clean_word):\n",
    "    output = [w for w in clean_word if w not in stop_words]\n",
    "    counts = Counter(output)\n",
    "    return counts\n",
    "    \n",
    "def loadtxt(filenames):\n",
    "    with open(filenames, 'r') as f:\n",
    "        x = f.readlines()\n",
    "#         print(x[0])\n",
    "        x[0] = x[0].lower()\n",
    "        #print(x[0])\n",
    "#         print(x)\n",
    "        filter_word = '[^a-zA-Z \\']'\n",
    "        clean_word = re.sub(filter_word, '', x[0])\n",
    "        data = clean_word.split()  #['...'] --> ['','','',...]\n",
    "#         for i in range(len(data)):\n",
    "#             clean_data = data[i].strip('\\'')\n",
    "        #print(data)\n",
    "        return clean_stopwords(data)\n",
    "\n",
    "def key_words(path):\n",
    "    frequency_bus = []\n",
    "    frequency_pol = []\n",
    "    frequency_spo = []\n",
    "    frequency_foo = []\n",
    "    for dir in os.listdir(path):\n",
    "        if dir == 'business':\n",
    "            business_path = os.path.join(path,'business')\n",
    "            os.chdir(business_path)\n",
    "            #count dataset\n",
    "            filenames = sorted(glob.glob('business*.txt'))\n",
    "            #print(filenames)\n",
    "            for i in filenames:\n",
    "                frequency_bus.append(loadtxt(str(i)))\n",
    "            print('Business')\n",
    "            print('-'*10)\n",
    "#             print(frequency_bus)\n",
    "            print('-'*100)\n",
    "            \n",
    "        elif dir == 'politics':\n",
    "            business_path = os.path.join(path,'politics')\n",
    "            os.chdir(business_path)\n",
    "            #count dataset\n",
    "            filenames = sorted(glob.glob('politics*.txt'))\n",
    "            for i in filenames:\n",
    "                frequency_pol.append(loadtxt(str(i)))\n",
    "            print('Politics')\n",
    "            print('-'*10)\n",
    "#             print(frequency_pol)\n",
    "            print('-'*100)\n",
    "            \n",
    "        elif dir == 'sports':\n",
    "            business_path = os.path.join(path,'sports')\n",
    "            os.chdir(business_path)\n",
    "            #count dataset\n",
    "            filenames = sorted(glob.glob('sports*.txt'))\n",
    "            for i in filenames:\n",
    "                frequency_spo.append(loadtxt(str(i)))\n",
    "            print('Sport')\n",
    "            print('-'*10)\n",
    "#             print(frequency_spo)\n",
    "            print('-'*100)\n",
    "        \n",
    "        elif dir =='science':\n",
    "            business_path = os.path.join(path,'science')\n",
    "            os.chdir(business_path)\n",
    "            #count dataset\n",
    "            filenames = sorted(glob.glob('science*.txt'))\n",
    "            for i in filenames:\n",
    "                frequency_foo.append(loadtxt(str(i)))\n",
    "            print('Science')\n",
    "            print('-'*10)\n",
    "#             print(frequency_foo)\n",
    "    return frequency_bus, frequency_pol, frequency_spo ,frequency_foo\n",
    "\n",
    "frequency_bus, frequency_pol, frequency_spo ,frequency_foo = key_words(PATH_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######get top words of each category\n",
    "def top_words_category(freq_list_category):\n",
    "    list_business = []\n",
    "    for i in range(len(freq_list_category)):\n",
    "        list_business.extend((freq_list_category[i]).most_common(250))  #top words of each txt\n",
    "    sorted_list = sorted(list_business, key = lambda tup: tup[1], reverse= True) #sort\n",
    "    top_bus = sorted_list[:250]  #top words of each category\n",
    "    return top_bus\n",
    "\n",
    "def combine_top_words(p, s, b, t):\n",
    "    Total_top_words = top_words_category(p) + top_words_category(s) + top_words_category(b) + top_words_category(t)\n",
    "    return Total_top_words\n",
    "\n",
    "##total words for each category\n",
    "top_word_business = top_words_category(frequency_bus)\n",
    "top_word_politics = top_words_category(frequency_pol)\n",
    "top_word_sport = top_words_category(frequency_spo)\n",
    "top_word_travel = top_words_category(frequency_foo)\n",
    "##total words for four category\n",
    "Total_top_words = combine_top_words(frequency_bus, frequency_pol, frequency_spo, frequency_foo)\n",
    "Total_top_words = [list(v) for v in dict(Total_top_words).items()]  ####unique key words\n",
    "# Total_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_top_words_list = []\n",
    "for i in range(len(Total_top_words)):\n",
    "    Total_top_words_list.append(Total_top_words[i][0])\n",
    "# Total_top_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_data_freq(p, s, b, t):\n",
    "    Total_List_counter = p + s + b + t\n",
    "    Total_List_dict = []\n",
    "    for i in range(len(Total_List_counter)):\n",
    "        Total_List_dict.append(dict(Total_List_counter[i]))\n",
    "    return Total_List_dict\n",
    "##total list_dict of all txt files\n",
    "Total_List_dict = combined_data_freq(frequency_bus, frequency_pol, frequency_spo, frequency_foo)\n",
    "# Total_List_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollar</th>\n",
       "      <th>food</th>\n",
       "      <th>bank</th>\n",
       "      <th>cable</th>\n",
       "      <th>reports</th>\n",
       "      <th>countrywide</th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>icahn</th>\n",
       "      <th>america</th>\n",
       "      <th>times</th>\n",
       "      <th>...</th>\n",
       "      <th>active</th>\n",
       "      <th>nurse</th>\n",
       "      <th>feed</th>\n",
       "      <th>medicine</th>\n",
       "      <th>oil</th>\n",
       "      <th>art</th>\n",
       "      <th>pecan</th>\n",
       "      <th>bod</th>\n",
       "      <th>foods</th>\n",
       "      <th>eggs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dollar food bank cable reports countrywide bitcoin icahn america times ...   \\\n",
       "0      0    0    6     0      14           0       0     0       3     7 ...    \n",
       "1      0    0    1    38       0           0       0     0       0     0 ...    \n",
       "2      0    0    0     0       0           0       0     0       0     0 ...    \n",
       "3      0    0    4     0       0           0       0     0       0     2 ...    \n",
       "4      0    0    0     0       0           0       0     0       0     1 ...    \n",
       "\n",
       "  active nurse feed medicine oil art pecan bod foods eggs  \n",
       "0      0     0    0        0   0   0     0   0     0    0  \n",
       "1      0     0    0        0   0   0     0   0     0    0  \n",
       "2      0     0    0        1   0   0     0   0     0    0  \n",
       "3      0     0    0        0   0   0     0   0     0    0  \n",
       "4      0     0    0        0   0   0     0   0     0    0  \n",
       "\n",
       "[5 rows x 606 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get each column name\n",
    "column_name_list = []\n",
    "for i in range(len(Total_top_words)):\n",
    "    column_name_list.append(Total_top_words[i][0])\n",
    "    \n",
    "##get each row name\n",
    "row_name_list=[]\n",
    "for i in range(len(Total_List_dict)):\n",
    "    row_name_list.append(i)\n",
    "\n",
    "\n",
    "Data_Frame = pd.DataFrame(index = row_name_list, columns = Total_top_words_list)\n",
    "# Data_Frame\n",
    "\n",
    "for col in range(len(column_name_list)): #for column\n",
    "    for row in range(len(row_name_list)):  #for row\n",
    "        if Total_List_dict[row].get(column_name_list[col]) is None:\n",
    "            Data_Frame.loc[row, column_name_list[col]] = 0\n",
    "        else:\n",
    "            Data_Frame.loc[row, column_name_list[col]] = Total_List_dict[row].get(column_name_list[col])\n",
    "pd.DataFrame.head(Data_Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollar</th>\n",
       "      <th>food</th>\n",
       "      <th>bank</th>\n",
       "      <th>cable</th>\n",
       "      <th>reports</th>\n",
       "      <th>countrywide</th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>icahn</th>\n",
       "      <th>america</th>\n",
       "      <th>times</th>\n",
       "      <th>...</th>\n",
       "      <th>nurse</th>\n",
       "      <th>feed</th>\n",
       "      <th>medicine</th>\n",
       "      <th>oil</th>\n",
       "      <th>art</th>\n",
       "      <th>pecan</th>\n",
       "      <th>bod</th>\n",
       "      <th>foods</th>\n",
       "      <th>eggs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dollar food bank cable reports countrywide bitcoin icahn america times  \\\n",
       "0      0    0    6     0      14           0       0     0       3     7   \n",
       "1      0    0    1    38       0           0       0     0       0     0   \n",
       "2      0    0    0     0       0           0       0     0       0     0   \n",
       "3      0    0    4     0       0           0       0     0       0     2   \n",
       "4      0    0    0     0       0           0       0     0       0     1   \n",
       "\n",
       "   ...  nurse feed medicine oil art pecan bod foods eggs label  \n",
       "0  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "1  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "2  ...      0    0        1   0   0     0   0     0    0   0.0  \n",
       "3  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "4  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "\n",
       "[5 rows x 607 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency_bus -> 0\n",
    "#frequency_pol -> 1\n",
    "#frequency_spo -> 2\n",
    "#frequency_foo -> 3\n",
    "a = len(frequency_bus) - 1\n",
    "b = len(frequency_bus) + len(frequency_pol) - 1\n",
    "c = len(frequency_bus) + len(frequency_pol) + len(frequency_spo) - 1\n",
    "\n",
    "Data_Frame.loc[0:a,'label'] = 0\n",
    "Data_Frame.loc[a+1:b,'label'] = 1\n",
    "Data_Frame.loc[b+1:c,'label'] = 2\n",
    "Data_Frame.loc[c+1:,'label'] = 3\n",
    "pd.DataFrame.head(Data_Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save as .csv\n",
    "Data_Frame.to_csv('/Users/maweibin/Desktop/data intensive computing/lab3/part2/data_0425/dataset.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 607)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maweibin/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "X = Data_Frame.iloc[:, 0:Data_Frame.shape[1]-1].values\n",
    "y = Data_Frame.iloc[:, Data_Frame.shape[1]-1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 111)\n",
    "\n",
    "# # # #Feature Scaling\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalizing\n",
    "normalizer = Normalizer()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.75 %\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_predknn = knn.predict(X_test)\n",
    "\n",
    "acc_knn = accuracy_score(y_test,y_predknn)*100\n",
    "print(round(acc_knn,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0 %\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_predlog = logreg.predict(X_test)\n",
    "\n",
    "acc_log = accuracy_score(y_test,y_predlog)*100\n",
    "print(round(acc_log,2,), \"%\")\n",
    "\n",
    "# C = [50, 20, 10, 1, .1, .001, .00001]\n",
    "# for c in C:\n",
    "#     clf = LogisticRegression(penalty='l2', C=c)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     print('C:', c)\n",
    "#     #print('Coefficient of each feature:', clf.coef_)\n",
    "#     print('Training accuracy:', clf.score(X_train, y_train))\n",
    "#     print('Test accuracy:', clf.score(X_test, y_test))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.25 %\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=200)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_predrf = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = accuracy_score(y_test,y_predrf)*100\n",
    "print(round(acc_random_forest,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.5 %\n"
     ]
    }
   ],
   "source": [
    "# SVM \n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predsvm = classifier.predict(X_test)\n",
    "\n",
    "acc_svm = accuracy_score(y_test,y_predsvm)*100\n",
    "print(round(acc_svm,2,), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business\n",
      "----------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Science\n",
      "----------\n",
      "Sport\n",
      "----------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Politics\n",
      "----------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred_freq_bus, pred_freq_pol, pred_freq_spo ,pred_freq_foo = key_words(PATH_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "######get top words of each category\n",
    "##total words for each category\n",
    "top_word_business = top_words_category(frequency_bus)\n",
    "top_word_politics = top_words_category(frequency_pol)\n",
    "top_word_sport = top_words_category(frequency_spo)\n",
    "top_word_travel = top_words_category(frequency_foo)\n",
    "##total words for four category\n",
    "Total_top_words1 = combine_top_words(pred_freq_bus, pred_freq_pol, pred_freq_spo, pred_freq_foo)\n",
    "Total_top_words1 = [list(v) for v in dict(Total_top_words1).items()]  ####unique key words\n",
    "# Total_top_words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##total list_dict of all txt files\n",
    "pred_total_List_dict = combined_data_freq(pred_freq_bus, pred_freq_pol, pred_freq_spo ,pred_freq_foo)\n",
    "# pred_total_List_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollar</th>\n",
       "      <th>food</th>\n",
       "      <th>bank</th>\n",
       "      <th>cable</th>\n",
       "      <th>reports</th>\n",
       "      <th>countrywide</th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>icahn</th>\n",
       "      <th>america</th>\n",
       "      <th>times</th>\n",
       "      <th>...</th>\n",
       "      <th>active</th>\n",
       "      <th>nurse</th>\n",
       "      <th>feed</th>\n",
       "      <th>medicine</th>\n",
       "      <th>oil</th>\n",
       "      <th>art</th>\n",
       "      <th>pecan</th>\n",
       "      <th>bod</th>\n",
       "      <th>foods</th>\n",
       "      <th>eggs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dollar food bank cable reports countrywide bitcoin icahn america times ...   \\\n",
       "0      0    0    0     0       0           0       0     0       0     2 ...    \n",
       "1      0    0    0     0       0           0       0     0       0     3 ...    \n",
       "2      0    0    0     0       0           0       0     0       0     2 ...    \n",
       "3      0    0    0     0       0           0       0     0       0     0 ...    \n",
       "4      0    0    0     0       0           0       0     0       0     0 ...    \n",
       "\n",
       "  active nurse feed medicine oil art pecan bod foods eggs  \n",
       "0      0     0    0        0   0   0     0   0     0    0  \n",
       "1      0     0    0        0   0   0     0   0     0    0  \n",
       "2      0     0    0        0   0   0     0   0     0    0  \n",
       "3      0     0    0        0   0   0     0   0     0    0  \n",
       "4      0     0    0        0   0   0     0   0     0    0  \n",
       "\n",
       "[5 rows x 606 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get each column name\n",
    "column_name_list = []\n",
    "for i in range(len(Total_top_words)):\n",
    "    column_name_list.append(Total_top_words[i][0])\n",
    "    \n",
    "##get each row name\n",
    "row_name_list=[]\n",
    "for i in range(len(pred_total_List_dict)):\n",
    "    row_name_list.append(i)\n",
    "\n",
    "\n",
    "Data_Frame_pred = pd.DataFrame(index = row_name_list, columns = Total_top_words_list)\n",
    "# Data_Frame_pred\n",
    "\n",
    "for col in range(len(column_name_list)): #for column\n",
    "    for row in range(len(row_name_list)):  #for row\n",
    "        if pred_total_List_dict[row].get(column_name_list[col]) is None:\n",
    "            Data_Frame_pred.loc[row, column_name_list[col]] = 0\n",
    "        else:\n",
    "            Data_Frame_pred.loc[row, column_name_list[col]] = pred_total_List_dict[row].get(column_name_list[col])\n",
    "pd.DataFrame.head(Data_Frame_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollar</th>\n",
       "      <th>food</th>\n",
       "      <th>bank</th>\n",
       "      <th>cable</th>\n",
       "      <th>reports</th>\n",
       "      <th>countrywide</th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>icahn</th>\n",
       "      <th>america</th>\n",
       "      <th>times</th>\n",
       "      <th>...</th>\n",
       "      <th>nurse</th>\n",
       "      <th>feed</th>\n",
       "      <th>medicine</th>\n",
       "      <th>oil</th>\n",
       "      <th>art</th>\n",
       "      <th>pecan</th>\n",
       "      <th>bod</th>\n",
       "      <th>foods</th>\n",
       "      <th>eggs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dollar food bank cable reports countrywide bitcoin icahn america times  \\\n",
       "0      0    0    0     0       0           0       0     0       0     2   \n",
       "1      0    0    0     0       0           0       0     0       0     3   \n",
       "2      0    0    0     0       0           0       0     0       0     2   \n",
       "3      0    0    0     0       0           0       0     0       0     0   \n",
       "4      0    0    0     0       0           0       0     0       0     0   \n",
       "\n",
       "   ...  nurse feed medicine oil art pecan bod foods eggs label  \n",
       "0  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "1  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "2  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "3  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "4  ...      0    0        0   0   0     0   0     0    0   0.0  \n",
       "\n",
       "[5 rows x 607 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency_bus -> 0\n",
    "#frequency_pol -> 1\n",
    "#frequency_spo -> 2\n",
    "#frequency_foo -> 3\n",
    "a = len(pred_freq_bus) - 1\n",
    "b = len(pred_freq_bus) + len(pred_freq_pol) - 1\n",
    "c = len(pred_freq_bus) + len(pred_freq_pol) + len(pred_freq_spo) - 1\n",
    "Data_Frame_pred.loc[0:a,'label'] = 0\n",
    "Data_Frame_pred.loc[a+1:b,'label'] = 1\n",
    "Data_Frame_pred.loc[b+1:c,'label'] = 2\n",
    "Data_Frame_pred.loc[c+1:,'label'] = 3\n",
    "pd.DataFrame.head(Data_Frame_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Randoming the rows\n",
    "# Data_Frame_pred = Data_Frame_pred.iloc[np.random.permutation(len(Data_Frame_pred))]\n",
    "# Data_Frame_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x_new = Data_Frame_pred.iloc[:,0:Data_Frame_pred.shape[1]-1].values\n",
    "y_new_pred = Data_Frame_pred.iloc[:,Data_Frame_pred.shape[1]-1].values\n",
    "\n",
    "# Feature Scaling\n",
    "# sc = StandardScaler()\n",
    "# sc = preprocessing.StandardScaler().fit(X)\n",
    "# # X_train = sc._transform(X_train)\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# x_new = sc.transform(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# normalizer = Normalizer()\n",
    "# X_train = normalizer.fit_transform(X_train)\n",
    "# X_test = normalizer.transform(X_test)\n",
    "x_new = normalizer.transform(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0 %\n"
     ]
    }
   ],
   "source": [
    "##KNN\n",
    "y_pred_knn = knn.predict(x_new)\n",
    "acc_knn1 = accuracy_score(y_pred_knn, y_new_pred)*100\n",
    "print(round(acc_knn1,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 %\n"
     ]
    }
   ],
   "source": [
    "##Logistic Regression\n",
    "y_pred_log = logreg.predict(x_new)\n",
    "acc_log1 = accuracy_score(y_pred_log, y_new_pred)*100\n",
    "print(round(acc_log1,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.5 %\n"
     ]
    }
   ],
   "source": [
    "##Random Forest\n",
    "y_pred_rf = random_forest.predict(x_new)\n",
    "acc_rf1 = accuracy_score(y_pred_rf, y_new_pred)*100\n",
    "print(round(acc_rf1,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.25 %\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "y_pred_svm = classifier.predict(x_new)\n",
    "acc_svm1 = accuracy_score(y_pred_svm, y_new_pred)*100\n",
    "print(round(acc_svm1,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 0. 3. 0. 3. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 3. 0. 1. 1. 1. 1.\n",
      " 3. 1. 3. 1. 1. 1. 1. 1. 1. 3. 1. 1. 1. 1. 1. 1. 1. 3. 0. 2. 1. 3. 3. 2.\n",
      " 2. 1. 3. 2. 2. 3. 2. 3. 3. 3. 3. 2. 3. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "[0. 2. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 3. 1. 3. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 0. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "[0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 3. 1. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 0. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "[0. 2. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 1. 1. 1. 1.\n",
      " 3. 1. 3. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 0. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_knn)\n",
    "print(y_pred_log)\n",
    "print(y_pred_rf)\n",
    "print(y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
